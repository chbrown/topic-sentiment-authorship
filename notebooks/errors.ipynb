{
 "metadata": {
  "name": "",
  "signature": "sha256:2344b4d93f518340d614c71946d50dc8be542dc9188cf37bd0c4dcff22f918f3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "from IPython.display import HTML\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import sparse\n",
      "from tsa.science import numpy_ext as npx\n",
      "from collections import Counter\n",
      "\n",
      "import viz\n",
      "\n",
      "from sklearn import metrics, cross_validation\n",
      "from sklearn import linear_model, svm, naive_bayes\n",
      "from sklearn import feature_selection\n",
      "\n",
      "from tsa import stdout, stderr\n",
      "from tsa.lib import tabular, datetime_extra, cache\n",
      "from tsa.lib.timer import Timer\n",
      "from tsa.models import Source, Document, create_session\n",
      "from tsa.science import features, timeseries\n",
      "from tsa.science.corpora import MulticlassCorpus\n",
      "from tsa.science.plot import plt, figure_path, distinct_styles, ticker\n",
      "from tsa.science.summarization import metrics_dict, metrics_summary\n",
      "\n",
      "import tsa.science.models\n",
      "from tsa.science.models import Bootstrap, SelectKBest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_corpus = MulticlassCorpus(Source.from_name('sb5b', labeled_only=True))\n",
      "full_corpus.apply_labelfunc(lambda doc: doc.label)\n",
      "full_corpus.extract_features(lambda doc: 1, features.intercept)\n",
      "full_corpus.extract_features(lambda doc: doc.document, features.ngrams,\n",
      "    ngram_max=2, min_df=2, max_df=1.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([    1,     2,     3, ..., 48118, 48119, 48120])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "polar_classes = [full_corpus.class_lookup[label] for label in ['For', 'Against']]\n",
      "polar_indices = np.in1d(full_corpus.y, polar_classes)\n",
      "polar_corpus = full_corpus.subset(rows=polar_indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "balanced_indices = npx.balance(polar_corpus.y == full_corpus.class_lookup['For'],\n",
      "                               polar_corpus.y == full_corpus.class_lookup['Against'])\n",
      "balanced_corpus = polar_corpus.subset(rows=balanced_indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to see how much we can improve accuracy if we let ourselves throw\n",
      "out some of the data. So, we take only the data with confidence above a certain\n",
      "threshold, and evaluate accuracy on that subset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bootstrap_model = Bootstrap(linear_model.LogisticRegression, n_iter=100, proportion=1.0,\n",
      "          fit_intercept=False, penalty='l2', C=1.0)\n",
      "logreg_model = linear_model.LogisticRegression(fit_intercept=False, penalty='l2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = polar_corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "folds = cross_validation.StratifiedShuffleSplit(corpus.y, test_size=0.1, n_iter=10)\n",
      "folds = list(folds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for train_indices, test_indices in folds:\n",
      "    train_corpus = corpus.subset(train_indices)\n",
      "    test_corpus = corpus.subset(test_indices)\n",
      "    logreg_model.fit(train_corpus.X, train_corpus.y)\n",
      "    \n",
      "    pred_proba = logreg_model.predict_proba(test_corpus.X)\n",
      "    pred_y = logreg_model.classes_[np.argmax(pred_proba, axis=1)]\n",
      "    print 'accuracy={:%} on all {:d} examples'.format(\n",
      "        metrics.accuracy_score(test_corpus.y, pred_y),\n",
      "        len(pred_y)\n",
      "    )\n",
      "\n",
      "    pred_confidence = 1 - (npx.hmean(pred_proba, axis=1)*2)\n",
      "    high_confidence_indices = pred_confidence > 0.90\n",
      "    \n",
      "    print 'accuracy={:%} on {:d} confident examples'.format(\n",
      "        metrics.accuracy_score(test_corpus.y[high_confidence_indices], pred_y[high_confidence_indices]),\n",
      "        high_confidence_indices.sum()\n",
      "    )\n",
      "    print\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy=96.404989% on all 1363 examples\n",
        "accuracy=99.309665% on 1014 confident examples\n",
        "\n",
        "accuracy=95.891416% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.219512% on 1025 confident examples\n",
        "\n",
        "accuracy=96.258254% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.036609% on 1038 confident examples\n",
        "\n",
        "accuracy=95.891416% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.319066% on 1028 confident examples\n",
        "\n",
        "accuracy=96.258254% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.306931% on 1010 confident examples\n",
        "\n",
        "accuracy=96.478357% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.216454% on 1021 confident examples\n",
        "\n",
        "accuracy=96.625092% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.415774% on 1027 confident examples\n",
        "\n",
        "accuracy=96.184886% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.224806% on 1032 confident examples\n",
        "\n",
        "accuracy=96.625092% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.606686% on 1017 confident examples\n",
        "\n",
        "accuracy=96.111519% on all 1363 examples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy=99.496982% on 994 confident examples\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_y = logreg_model.predict(test_corpus.X)\n",
      "pred_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([4, 0, 4, 4, 4, 4, 0, 4, 0, 0, 0, 0, 4, 4, 4, 4, 0, 4, 0, 0, 0, 0, 4,\n",
        "       0, 4, 4, 0, 0, 4, 0, 0, 4, 4, 0, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 0, 4,\n",
        "       0, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 0, 4, 0, 0,\n",
        "       4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 0, 0, 4, 0, 4, 4, 4,\n",
        "       0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 4, 4, 4, 0, 4, 0, 4, 0, 0, 4, 4, 0,\n",
        "       4, 4, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0,\n",
        "       4, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 4, 4, 0, 4,\n",
        "       0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 4, 0, 4, 0, 0, 0, 4, 4, 4, 0,\n",
        "       0, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4,\n",
        "       0, 4, 4, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0,\n",
        "       4, 0, 0, 4, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 4, 4, 4,\n",
        "       4, 4, 4, 0, 0, 0, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 0, 0, 4,\n",
        "       4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 0, 0, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0,\n",
        "       4, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 0,\n",
        "       0, 0, 0, 4, 4, 4, 4, 0, 0, 4, 0, 4, 0, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4,\n",
        "       0, 0, 4, 0, 4, 4, 4, 4, 4, 0, 0, 0, 4, 0, 0, 4, 4, 4, 0, 4, 0, 0, 4,\n",
        "       0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 0, 0,\n",
        "       0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0,\n",
        "       0, 0, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 0,\n",
        "       0, 4, 0, 4, 0, 0, 4, 4, 0, 0, 4, 0, 4, 0, 0, 4, 4, 4, 0, 0, 4, 4, 0,\n",
        "       0, 4, 0, 0, 4, 4, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0,\n",
        "       0, 4, 4, 0, 0, 0, 0, 4, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 4,\n",
        "       0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 0, 0, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0,\n",
        "       4, 4, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 0, 4,\n",
        "       4, 0, 0, 4])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_y_2 = "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(pred_y == pred_y_2).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_balanced_labels():\n",
      "    balanced_indices = npx.balance(corpus.y == corpus.labels['For'],\n",
      "                                   corpus.y == corpus.labels['Against'])\n",
      "    X = corpus.X[balanced_indices, :]\n",
      "    y = corpus.y[balanced_indices]\n",
      "    documents = corpus.documents[balanced_indices]\n",
      "    tweets = [corpus.tweets[index] for index in balanced_indices]\n",
      "    two_classes = np.array([corpus.labels['For'], corpus.labels['Against']])\n",
      "    classes = corpus.classes\n",
      "    labels = corpus.labels\n",
      "    feature_names = corpus.feature_names\n",
      "    del corpus\n",
      "    del balanced_indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = npx.indices(y)\n",
      "coefs_means = np.mean(bootstrap_coefs, axis=0)\n",
      "coefs_variances = np.var(bootstrap_coefs, axis=0)\n",
      "\n",
      "bootstrap_coefs = coefs_means\n",
      "# bootstrap_coefs = coefs_means / (coefs_variances + 1)\n",
      "# bootstrap_coefs = coefs_means / (coefs_variances + 1)**2\n",
      "\n",
      "# bootstrap_transformed is just a simple dot product with each token's coefficient,\n",
      "# which is a sum for each line-up of bag of words and coefficients\n",
      "bootstrap_transformed = X.dot(bootstrap_coefs)\n",
      "# we also want the variance of that, though, which may correlate with\n",
      "# the overall confidence of the model, or better: may explain some of\n",
      "# the residual that a simple dot product forgets about\n",
      "logger.info('Computing dot-variance')\n",
      "projections = X.toarray() * bootstrap_coefs\n",
      "# bootstrap_transformed == projections.sum(axis=1)\n",
      "projections_variance = projections.var(axis=1)\n",
      "\n",
      "class_1_probabilities = npx.logistic(bootstrap_transformed)\n",
      "bootstrap_pred_probabilities = np.column_stack((\n",
      "    1 - class_1_probabilities,\n",
      "    class_1_probabilities))\n",
      "bootstrap_max_column = np.argmax(bootstrap_pred_probabilities, axis=1)\n",
      "\n",
      "# class_columns = np.repeat(-1, classes.size)\n",
      "# class_columns[two_classes] = npx.indices(two_classes)\n",
      "# order = np.argsort(bootstrap_transformed)\n",
      "\n",
      "# pred_probs's first column is the probability of the label classes[pred_y[index]]\n",
      "# so we want to map pred_y[index], which is something like 3 or 4, to 0 or 1\n",
      "bootstrap_pred_y = two_classes[bootstrap_max_column]\n",
      "# bootstrap pred prob is the probability of the top class, over all classes\n",
      "# we want the additive inverse of the harmonic mean, as a way of\n",
      "# measuring the extremeness of the model's prediction\n",
      "# npx.hmean([0.1, 0.9]) == .18, npx.hmean([0.5, 0.5] == .5\n",
      "bootstrap_pred_confidence = 1 - (npx.hmean(bootstrap_pred_probabilities, axis=1)*2)\n",
      "# bootstrap_pred_confidence represents the adjusted confidence of a class, i.e.,\n",
      "# the probability of the chosen class but linearly normalized to somewhere between 0 and 1\n",
      "# more linear, instead of harmonic mean:\n",
      "# 1: min = 1  , nothing doing\n",
      "# 2: min =  .5, (x - 1/2)*(2/1) == 1 - (1 - x\n",
      "# 3: min = .33, (x - 1/3)*(3/2)\n",
      "# 4: min = .25, (x - 1/4)*(4/3)\n",
      "\n",
      "\n",
      "# plt.plot(a, label='up')\n",
      "# plt.plot(a, label='down')\n",
      "# plt.plot(npx.hmean(np.column_stack((a, b, c)), axis=1), label='hmean')\n",
      "\n",
      "# IPython.embed()\n",
      "\n",
      "print 'Bootstrap overall accuracy: %.4f' % metrics.accuracy_score(y, bootstrap_pred_y)\n",
      "# binned_accuracy(bootstrap_transformed, y, bootstrap_pred_y)\n",
      "\n",
      "errors_mask = bootstrap_pred_y != y\n",
      "logger.info('The model mis-predicted %d out of a total of %d', errors_mask.sum(), y.size)\n",
      "\n",
      "bounds = npx.bounds(bootstrap_transformed)\n",
      "print 'Transforms of mispredictions'\n",
      "hist(bootstrap_transformed[errors_mask], bounds)\n",
      "print 'Transforms of correct predictions'\n",
      "hist(bootstrap_transformed[~errors_mask], bounds)\n",
      "\n",
      "# hist((np.max(bootstrap_pred_probabilities[errors_mask], axis=1)-0.5)*2.0)\n",
      "def render_predictions_histograms():\n",
      "    plt.cla()\n",
      "    plt.hist((np.max(bootstrap_pred_probabilities[errors_mask], axis=1)-0.5)*2.0, bins=25)\n",
      "    plt.title('Mispredictions')\n",
      "    plt.xlabel('Probability of assigned label')\n",
      "    plt.ylabel('# of tweets')\n",
      "    plt.gcf().set_size_inches(8, 5)\n",
      "    plt.savefig(figure_path('hist-proba-incorrect.pdf'))\n",
      "\n",
      "    # hist((np.max(bootstrap_pred_probabilities[~errors_mask], axis=1)-0.5)*2.0)\n",
      "    plt.cla()\n",
      "    plt.hist((np.max(bootstrap_pred_probabilities[~errors_mask], axis=1)-0.5)*2.0, bins=25)\n",
      "    plt.title('Correct predictions')\n",
      "    plt.xlabel('Probability of assigned label')\n",
      "    plt.ylabel('# of tweets')\n",
      "    plt.gcf().set_size_inches(8, 5)\n",
      "    plt.savefig(figure_path('hist-proba-correct.pdf'))\n",
      "\n",
      "# errors_indices = balanced_indices[errors_mask]\n",
      "# pred_pairs = np.column_stack((bootstrap_pred_y, y))\n",
      "# Counter(zip(bootstrap_pred_y, y))\n",
      "\n",
      "# confusion_matrix = metrics.confusion_matrix(y, bootstrap_pred_y, range(len(classes)))\n",
      "# rownames = ['(Correct) ' + name for name in classes]\n",
      "# print pd.DataFrame(confusion_matrix, index=rownames, columns=classes)\n",
      "\n",
      "'''\n",
      "Negative, in this case, means \"For\"\n",
      "i.e., bootstrap_transformed[84] = -16.36, which shows the following SUPER \"For\"-SB5 tweet:\n",
      "    RT @GOHPBlog: ICYMI: Say 'YES' to Ohio jobs. Say 'YES' to\n",
      "    #Issue2 RT @BetterOhio: What Issue 2 means for Ohio Jobs: http://t.co/HJ8sL4l8 - #YesOn2\n",
      "positive, means \"Against\", here's bootstrap_transformed[2905] = 10.62:\n",
      "    RT @ProgressOhio: Ohio Issue 2: 30 TV Stations Pull Misleading Anti-Union Ad [UPDATE]\n",
      "    http://t.co/BUxxH3yz #p2 #1U #SB5 #Issue2 #WeAreOhio #StandUpOh #NoOn2\n",
      "'''\n",
      "\n",
      "\n",
      "# pred_y is an array of labels, like [3, 4, 4, 3, 4 ... 3, 4, 4, 4, 4]\n",
      "pred_y = bootstrap_pred_y\n",
      "pred_confidence = bootstrap_pred_confidence\n",
      "\n",
      "# def print_predictions(indices):\n",
      "selected_indices = []\n",
      "for index in selected_indices:\n",
      "    print '\\nModel predicted %r, annotated as %r' % (classes[pred_y[index]], classes[y[index]])\n",
      "    print 'Confidence in prediction = %0.5f, variance in = %0.5f' % (\n",
      "        pred_confidence[index], projections_variance[index])\n",
      "    print ' ', documents[index]\n",
      "    print\n",
      "    print\n",
      "\n",
      "# correct_indices_all = npx.bool_mask_to_indices(~errors_mask)\n",
      "# randomly pick up to 50\n",
      "# correct_indices_50 = np.random.choice(correct_indices_all, size=50, replace=False)\n",
      "ordering = pred_confidence.argsort()\n",
      "# ordering is from least confident to most confident\n",
      "incorrect_indices_ordered_by_confidence = indices[ordering][errors_mask[ordering]]\n",
      "correct_indices_ordered_by_confidence = indices[ordering][~errors_mask[ordering]]\n",
      "\n",
      "print '50 most confident correct predictions'\n",
      "selected_indices = correct_indices_ordered_by_confidence[-50:]\n",
      "\n",
      "print '50 least confident correct predictions'\n",
      "selected_indices = correct_indices_ordered_by_confidence[:50]\n",
      "\n",
      "print '50 most confident incorrect predictions'\n",
      "selected_indices = incorrect_indices_ordered_by_confidence[-50:]\n",
      "\n",
      "print '50 least confident incorrect predictions'\n",
      "selected_indices = incorrect_indices_ordered_by_confidence[:50]\n",
      "\n",
      "# print 'correct_indices_50.shape:', correct_indices_50.shape, 'y.shape:', y.shape\n",
      "# print 'bootstrap_pred_y.shape:', bootstrap_pred_y.shape, 'documents.shape', documents.shape\n",
      "# indices[]\n",
      "# classes[3]\n",
      "for_indices = indices[y == labels['For']]\n",
      "against_indices = indices[y == labels['Against']]\n",
      "plt.figure(111)\n",
      "plt.hist(pred_confidence[for_indices], bins=25)\n",
      "plt.figure(112)\n",
      "plt.hist(pred_confidence[against_indices], bins=25)\n",
      "\n",
      "\n",
      "# estBetaParams <- function(mu, var) {\n",
      "def fit_beta(xs):\n",
      "    # http://en.wikipedia.org/wiki/Beta_distribution\n",
      "    mean = np.mean(xs)\n",
      "    variance = np.var(xs)\n",
      "    bias = ((mean * (1 - mean)) / variance) - 1\n",
      "    alpha = mean * bias\n",
      "    beta = (1 - mean) * bias\n",
      "    return alpha, beta\n",
      "\n",
      "\n",
      "\n",
      "def plot_beta(alpha, beta):\n",
      "    grid = np.arange(100) / 100.0\n",
      "    # dist = np.random.beta(alpha, beta)\n",
      "    # ys = np.ran\n",
      "    plt.plot(grid, scipy.stats.beta.pdf(grid, alpha, beta), color='r')\n",
      "\n",
      "def data_with_beta(xs):\n",
      "    alpha, beta = fit_beta(xs)\n",
      "    plt.hist(xs)\n",
      "    plot_beta(alpha, beta)\n",
      "\n",
      "\n",
      "beta_support = np.arange(100) / 100.0\n",
      "\n",
      "\n",
      "\n",
      "plt.cla()\n",
      "xs = pred_confidence[against_indices]\n",
      "plt.hist(xs, normed=True, bins=25, color='r', alpha=0.5)\n",
      "alpha, beta = fit_beta(xs)\n",
      "plt.plot(beta_support, scipy.stats.beta.pdf(beta_support, alpha, beta), color='r', label='Against')\n",
      "\n",
      "xs = pred_confidence[for_indices]\n",
      "plt.hist(xs, normed=True, bins=25, color='b', alpha=0.5)\n",
      "alpha, beta = fit_beta(xs)\n",
      "plt.plot(beta_support, scipy.stats.beta.pdf(beta_support, alpha, beta), color='b', label='For')\n",
      "\n",
      "plt.title('Confidence by label')\n",
      "plt.xlabel('Higher = more confident')\n",
      "plt.ylabel('Density')\n",
      "plt.gcf().set_size_inches(8, 5)\n",
      "plt.savefig(figure_path('confidence-by-label.pdf'))\n",
      "\n",
      "\n",
      "\n",
      "# correct_indices_50\n",
      "shell(); exit()\n",
      "\n",
      "# most_extreme_to_least_extreme = np.argsort(-np.abs(bootstrap_transformed))\n",
      "print_predictions(correct_indices_50, y, bootstrap_pred_y, bootstrap_pred_probabilities, documents)\n",
      "# bootstrap_pred_probabilities\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "most_extreme_to_least_extreme = np.argsort(-np.abs(bootstrap_transformed))\n",
      "# ordered_most_extreme_to_least_extreme\n",
      "print 'Top 25 most extreme correct predictions'\n",
      "selected_indices = npx.bool_mask_to_indices(~errors_mask)\n",
      "print_predictions(selected_indices, y, bootstrap_pred_y, bootstrap_pred_probabilities, documents)\n",
      "\n",
      "IPython.embed() or exit()\n",
      "\n",
      "\n",
      "def old_describe(X, error_index):\n",
      "    x = X[error_index].toarray().ravel()\n",
      "    # could also just use the .indices of a CSR matrix\n",
      "    nonzero = x > 0\n",
      "    # total = coefs_means.dot(x)  # = sum(values)\n",
      "    x_names = feature_names[nonzero]\n",
      "    x_means = x[nonzero] * coefs_means[nonzero]\n",
      "    x_variances = x[nonzero] * coefs_variances[nonzero]\n",
      "    reordering = np.argsort(x_means)\n",
      "    # [('', '='), ('total', ])\n",
      "    print viz.gloss.gloss(\n",
      "        [('', 'means  ', 'vars')] + zip(\n",
      "            x_names[reordering],\n",
      "            map(flt, x_means[reordering]),\n",
      "            map(flt, x_variances[reordering]),\n",
      "        ) +\n",
      "        [('', '%.2f' % sum(x_means), '%.2f' % sum(x_variances))]\n",
      "    )\n",
      "\n",
      "# what is it that differentiates the hard-to-classify tweets near the middle vs.\n",
      "# the tweets near the middle that it gets right?\n",
      "\n",
      "biased_model = linear_model.LogisticRegression(fit_intercept=False)\n",
      "biased_model.fit(X, y)\n",
      "# biased_pred_y = biased_model.predict(X)\n",
      "# print 'Biased overall accuracy: %.4f' % metrics.accuracy_score(y, biased_pred_y)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}