{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from tsa.science import numpy_ext as npx\n",
      "from collections import Counter\n",
      "\n",
      "import viz\n",
      "\n",
      "from sklearn import metrics, cross_validation\n",
      "from sklearn import linear_model\n",
      "\n",
      "from tsa import stdout, stderr\n",
      "from tsa.lib import tabular, datetime_extra\n",
      "from tsa.lib.timer import Timer\n",
      "from tsa.models import Source, Document, create_session\n",
      "from tsa.science import features, models, timeseries\n",
      "from tsa.science.corpora import MulticlassCorpus\n",
      "from tsa.science.plot import plt, figure_path, distinct_styles, ticker\n",
      "from tsa.science.summarization import metrics_dict, metrics_summary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = Source.from_name('sb5b')\n",
      "full_corpus = MulticlassCorpus(documents)\n",
      "full_corpus.apply_labelfunc(lambda doc: doc.label)\n",
      "intercept_features = full_corpus.extract_features(lambda doc: 1, features.intercept)\n",
      "# liwc_counts, liwc_categories = features.liwc([doc.document for doc in full_corpus.data])\n",
      "liwc_features      = full_corpus.extract_features(lambda doc: doc.document, features.liwc)\n",
      "emo_features       = np.in1d(full_corpus.feature_names, ['posemo', 'negemo'])\n",
      "ngrams_features    = full_corpus.extract_features(lambda doc: doc.document,\n",
      "    features.ngrams, ngram_max=2, min_df=2, max_df=1.0)\n",
      "# ngram_max=2, min_df=0.001, max_df=0.95\n",
      "# print intercept_features.size, liwc_features.size, ngrams_features.size\n",
      "# full_corpus.X.tocsr()[rows, :].tocsc()[:, features]\n",
      "print full_corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<MulticlassCorpus X = (14383, 44521), y = (14383,)>\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "polar_classes = [full_corpus.class_lookup[label] for label in ['For', 'Against']]\n",
      "polar_indices = np.in1d(full_corpus.y, polar_classes)\n",
      "polar_corpus = full_corpus.subset(rows=polar_indices)\n",
      "print polar_corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<MulticlassCorpus X = (13627, 44521), y = (13627,)>\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def corpus_mean_accuracy(corpus, penalty='l2', test_size=0.1, n_iter=10):\n",
      "    folds = cross_validation.StratifiedShuffleSplit(corpus.y, test_size=test_size, n_iter=n_iter)\n",
      "    accuracies = []\n",
      "    for fold_index, (train_indices, test_indices) in enumerate(folds):\n",
      "        train_corpus = corpus.subset(train_indices)\n",
      "        test_corpus = corpus.subset(test_indices)\n",
      "    \n",
      "        model = linear_model.LogisticRegression(fit_intercept=False, penalty=penalty)\n",
      "        model.fit(train_corpus.X, train_corpus.y)\n",
      "        pred_y = model.predict(test_corpus.X)\n",
      "        accuracy = metrics.accuracy_score(test_corpus.y, pred_y)\n",
      "        accuracies += [accuracy]\n",
      "    return np.mean(accuracies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [\n",
      "                ('Unigrams, bigrams, LIWC', None),\n",
      "                ('Unigrams, bigrams', ngrams_features),\n",
      "                ('LIWC (all)', liwc_features),\n",
      "                ('LIWC (posemo, negemo)', emo_features),\n",
      "                ('LIWC (posemo)', full_corpus.feature_names == 'posemo'),\n",
      "                ('LIWC (negemo)', full_corpus.feature_names == 'negemo'),\n",
      "                ('Baseline', intercept_features),\n",
      "                ]\n",
      "for name, selected_features in feature_sets:\n",
      "    accuracy = corpus_mean_accuracy(polar_corpus.subset(features=selected_features))\n",
      "    print '{:s} & {:.2%} \\\\\\\\'.format(name, accuracy).replace('%', '\\\\%')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unigrams, bigrams, LIWC & 96.20%\\\\\n",
        "Unigrams, bigrams & 96.14%\\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (all) & 81.68%\\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (posemo, negemo) & 79.53%\\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (posemo) & 79.53%\\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (negemo) & 79.53%\\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Baseline & 79.53%\\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posemo_corpus = polar_corpus.subset(features=emo_features)\n",
      "Counter(posemo_corpus.y)\n",
      "print 'majority_class = {:.2%}'.format(10842. / (10842. + 2785.))\n",
      "# print posemo_corpus.X.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "majority_class = 79.56%\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### posemo / negemo correlation\n",
      "\n",
      "We want to show that posemo counts does not correlate with For / Against,\n",
      "but much more with volume. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "times = np.array([doc.published for doc in full_corpus.data]).astype('datetime64[s]')\n",
      "\n",
      "model = linear_model.LogisticRegression(fit_intercept=False, penalty='l2')\n",
      "model.fit(polar_corpus.X[:, ngrams_features], polar_corpus.y)\n",
      "full_corpus_pred_y = model.predict(full_corpus.X[:, ngrams_features])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[4 4 4 ..., 4 0 0]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print times.size, full_corpus_pred_y.size\n",
      "full_corpus_pred_labels = full_corpus.labels[full_corpus_pred_y]\n",
      "\n",
      "values = full_corpus_pred_labels.reshape(-1, 1)\n",
      "\n",
      "bin_edges, bin_values = timeseries.binned_timeseries(\n",
      "    times, values,\n",
      "    time_units_per_bin=7, time_unit='D', statistic='count')\n",
      "print bin_edges\n",
      "print bin_values.ravel()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14383 14383\n",
        "['2011-07-28T19:00:00-0500' '2011-08-04T19:00:00-0500'\n",
        " '2011-08-11T19:00:00-0500' '2011-08-18T19:00:00-0500'\n",
        " '2011-08-25T19:00:00-0500' '2011-09-01T19:00:00-0500'\n",
        " '2011-09-08T19:00:00-0500' '2011-09-15T19:00:00-0500'\n",
        " '2011-09-22T19:00:00-0500' '2011-09-29T19:00:00-0500'\n",
        " '2011-10-06T19:00:00-0500' '2011-10-13T19:00:00-0500'\n",
        " '2011-10-20T19:00:00-0500' '2011-10-27T19:00:00-0500'\n",
        " '2011-11-03T19:00:00-0500'] [  350.   449.   640.   570.   578.   437.   439.   522.   443.   732.\n",
        "   951.  1239.  1960.  1969.  3104.]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bins = dict(total=bin_values.ravel())\n",
      "for label in ['For', 'Against']:\n",
      "    indices = full_corpus_pred_y == full_corpus.class_lookup[label]\n",
      "    # by week\n",
      "\n",
      "    bin_edges, bin_values = timeseries.binned_timeseries(\n",
      "        times[indices], values[indices],\n",
      "        time_units_per_bin=7, time_unit='D', statistic='count')\n",
      "    bin_values = bin_values.ravel()\n",
      "    print bin_edges, bin_values\n",
      "    # bin_values = npx.exponential_decay(bin_values.ravel(), window=14, alpha=0.75)\n",
      "#     plt.plot(bin_edges, bin_values, label=label, **styles.next())\n",
      "\n",
      "# datetime64_formatter = datetime_extra.datetime64_formatter\n",
      "# axes = plt.gca()\n",
      "# axes.xaxis.set_major_formatter(ticker.FuncFormatter(datetime_extra.datetime64_formatter))\n",
      "# axes.grid(False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['2011-07-28T19:00:00-0500' '2011-08-04T19:00:00-0500'\n",
        " '2011-08-11T19:00:00-0500' '2011-08-18T19:00:00-0500'\n",
        " '2011-08-25T19:00:00-0500' '2011-09-01T19:00:00-0500'\n",
        " '2011-09-08T19:00:00-0500' '2011-09-15T19:00:00-0500'\n",
        " '2011-09-22T19:00:00-0500' '2011-09-29T19:00:00-0500'\n",
        " '2011-10-06T19:00:00-0500' '2011-10-13T19:00:00-0500'\n",
        " '2011-10-20T19:00:00-0500' '2011-10-27T19:00:00-0500'\n",
        " '2011-11-03T19:00:00-0500'] [  99.   94.   91.  123.   94.   29.   34.   30.   56.   92.   78.  170.\n",
        "  653.  812.  673.]\n",
        "['2011-07-28T19:00:00-0500' '2011-08-04T19:00:00-0500'\n",
        " '2011-08-11T19:00:00-0500' '2011-08-18T19:00:00-0500'\n",
        " '2011-08-25T19:00:00-0500' '2011-09-01T19:00:00-0500'\n",
        " '2011-09-08T19:00:00-0500' '2011-09-15T19:00:00-0500'\n",
        " '2011-09-22T19:00:00-0500' '2011-09-29T19:00:00-0500'\n",
        " '2011-10-06T19:00:00-0500' '2011-10-13T19:00:00-0500'\n",
        " '2011-10-20T19:00:00-0500' '2011-10-27T19:00:00-0500'\n",
        " '2011-11-03T19:00:00-0500'] [  251.   355.   549.   447.   484.   408.   405.   492.   387.   640.\n",
        "   873.  1069.  1307.  1157.  2431.]\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for liwc_category in ['posemo', 'negemo']:\n",
      "    plt.cla()\n",
      "    styles = distinct_styles()\n",
      "    counts = liwc_counts[:, liwc_categories.index(liwc_category)].toarray()\n",
      "    time_hist('Overall %s' % liwc_category, full_corpus_times, counts,\n",
      "        statistic='sum', **styles.next())\n",
      "    for label in ['For', 'Against']:\n",
      "        indices = full_pred_y == full_corpus.class_lookup[label]\n",
      "        time_hist('%s-class %s' % (label, liwc_category),\n",
      "            full_corpus_times[indices], counts[indices], statistic='sum', **styles.next())\n",
      "    plt.title('LIWC category: %s' % liwc_category)\n",
      "    plt.ylabel('Frequency')\n",
      "    plt.xlabel('Date')\n",
      "    axes = plt.gca()\n",
      "    axes.xaxis.set_major_formatter(ticker.FuncFormatter(datetime_extra.datetime64_formatter))\n",
      "    axes.grid(False)\n",
      "    plt.xlim(np.array(npx.bounds(full_corpus_times)).astype(float))\n",
      "    plt.gcf().set_size_inches(8, 5)\n",
      "    plt.legend(loc='best')\n",
      "    plt.savefig(figure_path('liwc-%s-for-vs-against.pdf' % liwc_category))\n",
      "\n",
      "raise IPython.embed()\n",
      "\n",
      "# convert vector to column matrix\n",
      "values = full_pred_y.reshape((-1, 1))\n",
      "\n",
      "plt.cla()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}