{
 "metadata": {
  "name": "",
  "signature": "sha256:b2c6096660c17c5ceb50a7bc1a9f191b479860e37e8c21e61673b293a1a08427"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython\n",
      "import re\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from tsa.science import numpy_ext as npx\n",
      "from collections import Counter\n",
      "\n",
      "import viz\n",
      "\n",
      "from sklearn import metrics, cross_validation\n",
      "from sklearn import linear_model\n",
      "\n",
      "from tsa import stdout, stderr\n",
      "from tsa.lib import tabular, datetime_extra\n",
      "from tsa.lib.timer import Timer\n",
      "from tsa.models import Source, Document, create_session\n",
      "from tsa.science import features, models, timeseries\n",
      "from tsa.science.corpora import MulticlassCorpus\n",
      "from tsa.science.plot import plt, figure_path, distinct_styles, ticker\n",
      "from tsa.science.summarization import metrics_dict, metrics_summary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = Source.from_name('sb5b')\n",
      "full_corpus = MulticlassCorpus(documents)\n",
      "full_corpus.apply_labelfunc(lambda doc: doc.label)\n",
      "# empty X will still have a shape of (1, 0)\n",
      "intercept_features = full_corpus.extract_features(lambda doc: 1, features.intercept)\n",
      "print full_corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<MulticlassCorpus X = (106702, 1), y = (106702,)>\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "polar_classes = [full_corpus.class_lookup[label] for label in ['For', 'Against']]\n",
      "polar_indices = np.in1d(full_corpus.y, polar_classes)\n",
      "polar_corpus = full_corpus.subset(rows=polar_indices)\n",
      "print polar_corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<MulticlassCorpus X = (13627, 1), y = (13627,)>\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# liwc_counts, liwc_categories = features.liwc([doc.document for doc in full_corpus.data])\n",
      "liwc_features      = polar_corpus.extract_features(lambda doc: doc.document, features.liwc)\n",
      "ngrams_features    = polar_corpus.extract_features(lambda doc: doc.document,\n",
      "    features.ngrams, ngram_max=2, min_df=2, max_df=1.0)\n",
      "# ngram_max=2, min_df=0.001, max_df=0.95\n",
      "all_features = np.concatenate([intercept_features, liwc_features, ngrams_features])\n",
      "print polar_corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<MulticlassCorpus X = (13627, 43449), y = (13627,)>\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posemo_features = npx.bool_mask_to_indices(polar_corpus.feature_names == 'posemo')\n",
      "negemo_features = npx.bool_mask_to_indices(polar_corpus.feature_names == 'negemo')\n",
      "emo_features    = npx.bool_mask_to_indices(\n",
      "    np.in1d(polar_corpus.feature_names, ['posemo', 'negemo']))\n",
      "# liwc_features, all_features\n",
      "print posemo_features, negemo_features, emo_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[43] [38] [38 43]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "(1,)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def corpus_mean_accuracy(corpus, penalty='l2', test_size=0.1, n_iter=10):\n",
      "    folds = cross_validation.StratifiedShuffleSplit(corpus.y, test_size=test_size, n_iter=n_iter)\n",
      "    accuracies = []\n",
      "    for fold_index, (train_indices, test_indices) in enumerate(folds):\n",
      "        train_corpus = corpus.subset(train_indices)\n",
      "        test_corpus = corpus.subset(test_indices)\n",
      "    \n",
      "        model = linear_model.LogisticRegression(fit_intercept=False, penalty=penalty)\n",
      "        model.fit(train_corpus.X, train_corpus.y)\n",
      "        pred_y = model.predict(test_corpus.X)\n",
      "        accuracy = metrics.accuracy_score(test_corpus.y, pred_y)\n",
      "        accuracies += [accuracy]\n",
      "    return np.mean(accuracies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = [\n",
      "                ('Unigrams, bigrams, LIWC', all_features),\n",
      "                ('Unigrams, bigrams', ngrams_features),\n",
      "                ('LIWC (all)', liwc_features),\n",
      "                ('LIWC (posemo, negemo)', emo_features),\n",
      "                ('LIWC (posemo)', posemo_features),\n",
      "                ('LIWC (negemo)', negemo_features),\n",
      "                ('Baseline', intercept_features),\n",
      "               ]\n",
      "\n",
      "print '{:s} & {:s} & {:s} \\\\\\\\'.format('Features', 'Number of features', 'Accuracy')\n",
      "for name, selected_features in feature_sets:\n",
      "    subcorpus = polar_corpus.subset(features=selected_features)\n",
      "    accuracy = corpus_mean_accuracy(subcorpus)    \n",
      "    print '{:s} & {:d} & {:.2%} \\\\\\\\'.format(\n",
      "        name, selected_features.size, accuracy).replace('%', '\\\\%')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features & Number of features & Accuracy \\\\\n",
        "Unigrams, bigrams, LIWC & 43449 & 96.10\\% \\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Unigrams, bigrams & 43384 & 96.09\\% \\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (all) & 64 & 81.67\\% \\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (posemo, negemo) & 2 & 52.58\\% \\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (posemo) & 1 & 41.75\\% \\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LIWC (negemo) & 1 & 39.33\\% \\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Baseline & 1 & 79.53\\% \\\\"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posemo_corpus = polar_corpus.subset(features=emo_features)\n",
      "Counter(posemo_corpus.y)\n",
      "print 'majority_class = {:.2%}'.format(10842. / (10842. + 2785.))\n",
      "# print posemo_corpus.X.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "majority_class = 79.56%\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### posemo / negemo correlation\n",
      "\n",
      "We want to show that posemo counts does not correlate with For / Against,\n",
      "but much more with volume. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "times = np.array([doc.published for doc in full_corpus.data]).astype('datetime64[s]')\n",
      "\n",
      "model = linear_model.LogisticRegression(fit_intercept=False, penalty='l2')\n",
      "model.fit(polar_corpus.X[:, ngrams_features], polar_corpus.y)\n",
      "full_corpus_pred_y = model.predict(full_corpus.X[:, ngrams_features])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[4 4 4 ..., 4 0 0]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print times.size, full_corpus_pred_y.size\n",
      "full_corpus_pred_labels = full_corpus.labels[full_corpus_pred_y]\n",
      "\n",
      "values = full_corpus_pred_labels.reshape(-1, 1)\n",
      "\n",
      "bin_edges, bin_values = timeseries.binned_timeseries(\n",
      "    times, values,\n",
      "    time_units_per_bin=7, time_unit='D', statistic='count')\n",
      "print bin_edges\n",
      "print bin_values.ravel()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14383 14383\n",
        "['2011-07-28T19:00:00-0500' '2011-08-04T19:00:00-0500'\n",
        " '2011-08-11T19:00:00-0500' '2011-08-18T19:00:00-0500'\n",
        " '2011-08-25T19:00:00-0500' '2011-09-01T19:00:00-0500'\n",
        " '2011-09-08T19:00:00-0500' '2011-09-15T19:00:00-0500'\n",
        " '2011-09-22T19:00:00-0500' '2011-09-29T19:00:00-0500'\n",
        " '2011-10-06T19:00:00-0500' '2011-10-13T19:00:00-0500'\n",
        " '2011-10-20T19:00:00-0500' '2011-10-27T19:00:00-0500'\n",
        " '2011-11-03T19:00:00-0500'] [  350.   449.   640.   570.   578.   437.   439.   522.   443.   732.\n",
        "   951.  1239.  1960.  1969.  3104.]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bins = dict(total=bin_values.ravel())\n",
      "for label in ['For', 'Against']:\n",
      "    indices = full_corpus_pred_y == full_corpus.class_lookup[label]\n",
      "    # by week\n",
      "\n",
      "    bin_edges, bin_values = timeseries.binned_timeseries(\n",
      "        times[indices], values[indices],\n",
      "        time_units_per_bin=7, time_unit='D', statistic='count')\n",
      "    bin_values = bin_values.ravel()\n",
      "    print bin_edges, bin_values\n",
      "    # bin_values = npx.exponential_decay(bin_values.ravel(), window=14, alpha=0.75)\n",
      "#     plt.plot(bin_edges, bin_values, label=label, **styles.next())\n",
      "\n",
      "# datetime64_formatter = datetime_extra.datetime64_formatter\n",
      "# axes = plt.gca()\n",
      "# axes.xaxis.set_major_formatter(ticker.FuncFormatter(datetime_extra.datetime64_formatter))\n",
      "# axes.grid(False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['2011-07-28T19:00:00-0500' '2011-08-04T19:00:00-0500'\n",
        " '2011-08-11T19:00:00-0500' '2011-08-18T19:00:00-0500'\n",
        " '2011-08-25T19:00:00-0500' '2011-09-01T19:00:00-0500'\n",
        " '2011-09-08T19:00:00-0500' '2011-09-15T19:00:00-0500'\n",
        " '2011-09-22T19:00:00-0500' '2011-09-29T19:00:00-0500'\n",
        " '2011-10-06T19:00:00-0500' '2011-10-13T19:00:00-0500'\n",
        " '2011-10-20T19:00:00-0500' '2011-10-27T19:00:00-0500'\n",
        " '2011-11-03T19:00:00-0500'] [  99.   94.   91.  123.   94.   29.   34.   30.   56.   92.   78.  170.\n",
        "  653.  812.  673.]\n",
        "['2011-07-28T19:00:00-0500' '2011-08-04T19:00:00-0500'\n",
        " '2011-08-11T19:00:00-0500' '2011-08-18T19:00:00-0500'\n",
        " '2011-08-25T19:00:00-0500' '2011-09-01T19:00:00-0500'\n",
        " '2011-09-08T19:00:00-0500' '2011-09-15T19:00:00-0500'\n",
        " '2011-09-22T19:00:00-0500' '2011-09-29T19:00:00-0500'\n",
        " '2011-10-06T19:00:00-0500' '2011-10-13T19:00:00-0500'\n",
        " '2011-10-20T19:00:00-0500' '2011-10-27T19:00:00-0500'\n",
        " '2011-11-03T19:00:00-0500'] [  251.   355.   549.   447.   484.   408.   405.   492.   387.   640.\n",
        "   873.  1069.  1307.  1157.  2431.]\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for liwc_category in ['posemo', 'negemo']:\n",
      "    plt.cla()\n",
      "    styles = distinct_styles()\n",
      "    counts = liwc_counts[:, liwc_categories.index(liwc_category)].toarray()\n",
      "    time_hist('Overall %s' % liwc_category, full_corpus_times, counts,\n",
      "        statistic='sum', **styles.next())\n",
      "    for label in ['For', 'Against']:\n",
      "        indices = full_pred_y == full_corpus.class_lookup[label]\n",
      "        time_hist('%s-class %s' % (label, liwc_category),\n",
      "            full_corpus_times[indices], counts[indices], statistic='sum', **styles.next())\n",
      "    plt.title('LIWC category: %s' % liwc_category)\n",
      "    plt.ylabel('Frequency')\n",
      "    plt.xlabel('Date')\n",
      "    axes = plt.gca()\n",
      "    axes.xaxis.set_major_formatter(ticker.FuncFormatter(datetime_extra.datetime64_formatter))\n",
      "    axes.grid(False)\n",
      "    plt.xlim(np.array(npx.bounds(full_corpus_times)).astype(float))\n",
      "    plt.gcf().set_size_inches(8, 5)\n",
      "    plt.legend(loc='best')\n",
      "    plt.savefig(figure_path('liwc-%s-for-vs-against.pdf' % liwc_category))\n",
      "\n",
      "raise IPython.embed()\n",
      "\n",
      "# convert vector to column matrix\n",
      "values = full_pred_y.reshape((-1, 1))\n",
      "\n",
      "plt.cla()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LIWC visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lexicons import Liwc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexicon = Liwc()\n",
      "document = \"\"\"I do live in OH, \\& yes, it's awful. NO on \\#Issue2  RT @RachelAnneLevy: I don't live in Ohio but from what i can tell \\#sb5 sounds awful.\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter = Counter(lexicon.read_document(document))\n",
      "print counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counter({u'funct': 14, u'pronoun': 5, u'verb': 4, u'auxverb': 4, u'preps': 4, u'present': 4, u'ppron': 3, u'i': 3, u'space': 3, u'relativ': 3, u'cogmech': 2, u'ipron': 2, u'assent': 2, u'negemo': 2, u'negate': 2, u'affect': 2, u'hear': 1, u'percept': 1, u'conj': 1, u'social': 1, u'excl': 1})\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for category, count in counter.most_common(100):\n",
      "    print '%s\\t%s' % (category, count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "funct\t14\n",
        "pronoun\t5\n",
        "verb\t4\n",
        "auxverb\t4\n",
        "preps\t4\n",
        "present\t4\n",
        "ppron\t3\n",
        "i\t3\n",
        "space\t3\n",
        "relativ\t3\n",
        "cogmech\t2\n",
        "ipron\t2\n",
        "assent\t2\n",
        "negemo\t2\n",
        "negate\t2\n",
        "affect\t2\n",
        "hear\t1\n",
        "percept\t1\n",
        "conj\t1\n",
        "social\t1\n",
        "excl\t1\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for match in re.finditer(r\"[a-z]['a-z]*\", document, re.I):\n",
      "    token = match.group(0)\n",
      "    matches = [match for match in lexicon.read_token(token.lower())]\n",
      "    print '%s & %s' % (token, ' & '.join(matches))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I & funct & pronoun & ppron & i\n",
        "do & verb & funct & auxverb & present\n",
        "live & \n",
        "in & funct & preps & space & relativ\n",
        "OH & assent\n",
        "yes & assent\n",
        "it's & funct & pronoun & ipron & verb & auxverb & present\n",
        "awful & affect & negemo\n",
        "NO & funct & negate\n",
        "on & funct & preps & space & relativ\n",
        "Issue & cogmech\n",
        "RT & \n",
        "RachelAnneLevy & \n",
        "I & funct & pronoun & ppron & i\n",
        "don't & verb & funct & auxverb & present & negate\n",
        "live & \n",
        "in & funct & preps & space & relativ\n",
        "Ohio & \n",
        "but & funct & conj & cogmech & excl\n",
        "from & funct & preps\n",
        "what & funct & pronoun & ipron\n",
        "i & funct & pronoun & ppron & i\n",
        "can & verb & funct & auxverb & present\n",
        "tell & social\n",
        "sb & \n",
        "sounds & percept & hear\n",
        "awful & affect & negemo\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}